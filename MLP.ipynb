{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "783af192-25e8-4f29-936a-95cedbed963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25ed4242-6192-4e7f-962e-eef71a2db15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4724b45-f5e5-44bc-9819-17ba1481ef5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1f00f2f-f84c-4166-a1a8-3f6d89240e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# build vocabulary of characters and mapping to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i for i,s in enumerate(chars,1)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5d50859-1583-4c0e-a79b-b3dac9719486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ----> e\n",
      "..e ----> m\n",
      ".em ----> m\n",
      "emm ----> a\n",
      "mma ----> .\n",
      "olivia\n",
      "... ----> o\n",
      "..o ----> l\n",
      ".ol ----> i\n",
      "oli ----> v\n",
      "liv ----> i\n",
      "ivi ----> a\n",
      "via ----> .\n",
      "ava\n",
      "... ----> a\n",
      "..a ----> v\n",
      ".av ----> a\n",
      "ava ----> .\n",
      "isabella\n",
      "... ----> i\n",
      "..i ----> s\n",
      ".is ----> a\n",
      "isa ----> b\n",
      "sab ----> e\n",
      "abe ----> l\n",
      "bel ----> l\n",
      "ell ----> a\n",
      "lla ----> .\n",
      "sophia\n",
      "... ----> s\n",
      "..s ----> o\n",
      ".so ----> p\n",
      "sop ----> h\n",
      "oph ----> i\n",
      "phi ----> a\n",
      "hia ----> .\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3   #content length: how many chracters do we take to predict the next one?\n",
    "X, Y = [], []\n",
    "for w in words[:5]:\n",
    "\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(''.join(itos[i] for i in context), '---->', itos[ix])\n",
    "\n",
    "        #crop and append\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80d560d3-2c98-4046-b5c9-49132eff7501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17c8b6d4-d441-4fd5-a752-3fcdfe482df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((27,2))  #2 dimension embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5d9e835-bf56-4851-93bc-1d08d94e0129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0298, 1.0701])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a70c29e-8da1-4e26-9800-f11f4f9dfcf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0298, 1.0701])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(5), num_classes=27).float() @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "200822a2-eedd-4cce-85ec-574ed95fb3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0298,  1.0701],\n",
       "        [ 2.7273, -1.4027],\n",
       "        [ 1.0933, -0.6301],\n",
       "        [ 1.0933, -0.6301],\n",
       "        [ 1.0933, -0.6301]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[torch.tensor([5,6,7,7,7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e08a58e2-4863-453f-bfd3-20148c15da54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46265e60-1940-4d05-882c-2c5ddd20cef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[13,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91fcef02-2098-4db2-88d7-446feeded6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.7667, -0.9673])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X][13,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9aad8302-434e-4e43-8a52-6b49d85db4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.7667, -0.9673])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2beb7d88-153b-4bbe-825b-8f78be7ecc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c0de514-f247-4074-866a-3d0b7956e129",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn((6, 100))  #(no.of inputs, neurons)      #no. of i/p-> (batch)*(2d-embd)\n",
    "b1 = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52847f16-ccc0-4bc3-9fa6-b1634cf8b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#emb @ w1 + b1   # 32,3,2 @ 6,100   not possible need to concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccfcdb93-1e66-4d9b-ad80-fd1c2791e554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb[:, 0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c8b1e81-8c6d-49af-85fd-18b74034bd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]], 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3327133c-02ce-4c38-a434-54948f18bb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(torch.unbind(emb, 1),1 ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "598d0e12-2bb9-4857-958b-c3f610523d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(18)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e63939db-4f8e-4611-bc33-8371b4072505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb75cdbc-2803-40e6-9248-67e186cc789e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12, 13, 14, 15, 16, 17]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(2,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "85181c85-0385-431e-8097-cbf1e95e65c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3],\n",
       "         [ 4,  5]],\n",
       "\n",
       "        [[ 6,  7],\n",
       "         [ 8,  9],\n",
       "         [10, 11]],\n",
       "\n",
       "        [[12, 13],\n",
       "         [14, 15],\n",
       "         [16, 17]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(3,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5072c3dc-7463-4cce-b25e-28e482d1a0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12106/214256462.py:1: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  a.storage()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 17\n",
       "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 18]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1fbb0240-cc0b-4351-b6d6-a87bf8e72609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(32,6).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "593e6b76-7d50-4fea-9c7a-bafdd04d2bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(32,6) == torch.cat(torch.unbind(emb, 1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8146d3e-556a-4515-b8a4-f9f7cf695249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0156,  0.9029,  1.3852,  ...,  0.1527,  1.2015,  1.3162],\n",
       "        [ 2.4521,  0.1809,  4.4049,  ..., -1.8752,  1.1763, -2.2466],\n",
       "        [ 0.7197,  6.0725,  2.1046,  ...,  0.6129,  2.5786, -1.0459],\n",
       "        ...,\n",
       "        [ 4.7558, -4.4562,  0.5370,  ..., -3.4186, -0.9359,  1.9618],\n",
       "        [ 3.7840,  2.2373,  3.0705,  ..., -4.9853,  1.8427, -2.6250],\n",
       "        [-2.0735,  4.3307,  0.5233,  ...,  5.3070,  2.2392,  3.9314]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(32,6) @ W1 + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "40b254dc-79d5-45a6-87e1-003a95680e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0156,  0.9029,  1.3852,  ...,  0.1527,  1.2015,  1.3162],\n",
       "        [ 2.4521,  0.1809,  4.4049,  ..., -1.8752,  1.1763, -2.2466],\n",
       "        [ 0.7197,  6.0725,  2.1046,  ...,  0.6129,  2.5786, -1.0459],\n",
       "        ...,\n",
       "        [ 4.7558, -4.4562,  0.5370,  ..., -3.4186, -0.9359,  1.9618],\n",
       "        [ 3.7840,  2.2373,  3.0705,  ..., -4.9853,  1.8427, -2.6250],\n",
       "        [-2.0735,  4.3307,  0.5233,  ...,  5.3070,  2.2392,  3.9314]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(emb.shape[0], 2*block_size) @ W1 + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9d555fa9-83e0-4218-ae57-3e380bd85d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0156,  0.9029,  1.3852,  ...,  0.1527,  1.2015,  1.3162],\n",
       "        [ 2.4521,  0.1809,  4.4049,  ..., -1.8752,  1.1763, -2.2466],\n",
       "        [ 0.7197,  6.0725,  2.1046,  ...,  0.6129,  2.5786, -1.0459],\n",
       "        ...,\n",
       "        [ 4.7558, -4.4562,  0.5370,  ..., -3.4186, -0.9359,  1.9618],\n",
       "        [ 3.7840,  2.2373,  3.0705,  ..., -4.9853,  1.8427, -2.6250],\n",
       "        [-2.0735,  4.3307,  0.5233,  ...,  5.3070,  2.2392,  3.9314]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(emb.shape[0], 6) @ W1 + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dbd984f6-0b9e-47ef-8ef6-9c774238f891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7681,  0.7177,  0.8821,  ...,  0.1515,  0.8341,  0.8658],\n",
       "        [ 0.9853,  0.1789,  0.9997,  ..., -0.9541,  0.8263, -0.9779],\n",
       "        [ 0.6167,  1.0000,  0.9707,  ...,  0.5462,  0.9886, -0.7802],\n",
       "        ...,\n",
       "        [ 0.9999, -0.9997,  0.4907,  ..., -0.9979, -0.7333,  0.9612],\n",
       "        [ 0.9990,  0.9775,  0.9957,  ..., -0.9999,  0.9511, -0.9896],\n",
       "        [-0.9689,  0.9997,  0.4802,  ...,  1.0000,  0.9776,  0.9992]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4c81f265-e583-400b-ac30-bc230e2d5837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "97266a33-9330-473e-a0bd-7c31ce68cb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(emb.view(-1,6) @ W1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e177bfd7-7bef-41a8-a450-9a7c0c939a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a97ad14a-7480-4398-b851-2fa431621f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# broadcasting\n",
    "# 32, 100\n",
    "#  1 , 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3b8dd807-1c90-437d-b313-5106a14b514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "078e4224-2eb0-4822-87ef-c0a3153c2fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "680ce1c2-a6f1-4e2a-bccb-f33bb3da08a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fa00c10c-3f02-4f4b-824c-b3ac30d0ea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eda0b504-80d0-43f1-9552-d3048fa04988",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = counts / counts.sum(1, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4492e94b-97b9-4034-8734-f46f84a7e0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9df01c34-1c63-4a30-841b-532f59e36d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.4573e-04, 1.0719e-08, 7.1504e-08, 1.5865e-07, 5.1512e-08, 1.9140e-08,\n",
       "        7.6289e-04, 8.2651e-03, 2.8533e-04, 1.9996e-01, 1.7398e-06, 7.8940e-01,\n",
       "        1.3441e-07, 1.3384e-06, 2.8535e-07, 9.5158e-09, 1.2380e-05, 1.8517e-04,\n",
       "        6.8198e-05, 9.0649e-05, 3.7874e-06, 1.3876e-13, 7.2711e-10, 9.6407e-06,\n",
       "        3.0877e-10, 8.7183e-08, 2.5344e-06])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[0]  # showing prob of every ch for 0th sample, now need to pick that index which is expected to be correct.\n",
    "#prob[0,Y[0]] shows what is the prob of expected output if it is 1 it means it found correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a952f045-899f-4247-8202-e0b1a4fd205e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.3580)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -prob[torch.arange(32),Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c292f5d3-d07a-4718-b354-635d92b84628",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = F.one_hot(Y, num_classes= 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ef07190a-a23d-49a8-bb7c-44bb49dcd64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0d681597-0634-41dd-ad84-9bc2ff59ebd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a9177d48-96c5-4fad-8be6-e6d606d0f351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.3580)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(logits, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6a223cae-1196-4641-b067-818999a9072d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.Size([32]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6de9cfef-39c9-429b-9858-1221720c0928",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27,2), generator=g)\n",
    "W1 = torch.randn((6,100),generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100,27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3fcd6260-c93a-465d-a607-f3fda8b19ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters)  #total parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0ea14dcb-3191-4a99-ab5f-12a65e78a77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "27*2 + 6*100 + 100 + 100*27 + 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "50c7ede2-e4e9-40b5-8dad-ba3a78a564f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.7697)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "h = torch.tanh(emb.view(-1,6) @ W1 + b1)  #(32,100)\n",
    "logits = h @ W2 + b2 #(32,27)\n",
    "# counts = logits.exp()\n",
    "# prob = counts / counts.sum(1, keepdims=True)\n",
    "# loss = -prob[torch.arange(32),Y].log().mean()\n",
    "loss = F.cross_entropy(logits,Y)                #clustered the operation and efficient\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e03b52-1d63-4643-b875-7be7bd3b99c3",
   "metadata": {},
   "source": [
    "# torch.nn.functional.cross_entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7bd52f52-5c0a-453a-8e10-62f62f937dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., nan])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.tensor([-100,3,0,100])\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum()\n",
    "probs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2464b4ba-176d-4744-8b21-a6d17680c3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.7835e-44, 2.0086e+01, 1.0000e+00,        inf])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts #so that means we can't pass very large logits to the expresion it will lead to inf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "294b074f-9b22-4078-a127-26508a9e9785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.9751e-05, 1.1849e-01, 5.8995e-03, 8.7557e-01])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.tensor([-5,3,0,5])\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum()\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3f442b68-0a21-438a-954d-5e270054bb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.7379e-03, 2.0086e+01, 1.0000e+00, 1.4841e+02])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "128ade08-1979-4a9d-9630-682f0673b3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 7.4689e-43, 3.7835e-44, 1.0000e+00])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you know how the exponential go like 0 to infinity\n",
    "# so how pytorch handle it by subtracting \n",
    "# as negative no. doesn't cause problem but postive does\n",
    "logits = torch.tensor([-100,3,0,100]) - 100\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum()\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2268a5-9c53-44d5-a81d-2168144fa830",
   "metadata": {},
   "source": [
    "# ---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1b0b73d4-6bf1-43c8-adac-35e151272003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3   #content length: how many chracters do we take to predict the next one?\n",
    "X, Y = [], []\n",
    "for w in words:\n",
    "\n",
    "    #print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        #print(''.join(itos[i] for i in context), '---->', itos[ix])\n",
    "\n",
    "        #crop and append\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "864668de-59d9-438e-ae97-206745382bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.Size([228146]))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "59322717-9e1f-466f-851c-3e8b6c42b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27,2), generator=g)\n",
    "W1 = torch.randn((6,100),generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100,27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "60e3a5b5-e40b-4c47-bd25-da53f3043490",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6edb010e-bff0-4fbd-b9d3-a3636f372f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3018555641174316\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1000):\n",
    "\n",
    "    #mini-batch construct\n",
    "    ix = torch.randint(0, X.shape[0], (32,))\n",
    "    \n",
    "    # forward pass\n",
    "    emb = C[X[ix]]  #(32, 3, 2)\n",
    "    h = torch.tanh(emb.view(-1,6) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y[ix])\n",
    "    \n",
    "    \n",
    "    #backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    #update\n",
    "    for p in parameters:\n",
    "        p.data +=  -0.1 *p.grad\n",
    "        \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "59ff286e-169c-4077-b653-07c87a19e456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([207650,  48820, 184742,  74151,  87370, 120456, 108412, 139639, 153970,\n",
       "        111493,    560,   2019,  26536,  42317, 162014,  36741, 123183, 217723,\n",
       "        171405,  43999,  24071, 197782,  51893,  83002, 200819,  82871, 156836,\n",
       "        139234,  83021, 220494,   8653, 216284])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0,X.shape[0], (32,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94cb164-5c3a-474a-b95d-ae34a8a18da4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
