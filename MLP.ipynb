{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "783af192-25e8-4f29-936a-95cedbed963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25ed4242-6192-4e7f-962e-eef71a2db15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4724b45-f5e5-44bc-9819-17ba1481ef5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1f00f2f-f84c-4166-a1a8-3f6d89240e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# build vocabulary of characters and mapping to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i for i,s in enumerate(chars,1)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5d50859-1583-4c0e-a79b-b3dac9719486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ----> e\n",
      "..e ----> m\n",
      ".em ----> m\n",
      "emm ----> a\n",
      "mma ----> .\n",
      "olivia\n",
      "... ----> o\n",
      "..o ----> l\n",
      ".ol ----> i\n",
      "oli ----> v\n",
      "liv ----> i\n",
      "ivi ----> a\n",
      "via ----> .\n",
      "ava\n",
      "... ----> a\n",
      "..a ----> v\n",
      ".av ----> a\n",
      "ava ----> .\n",
      "isabella\n",
      "... ----> i\n",
      "..i ----> s\n",
      ".is ----> a\n",
      "isa ----> b\n",
      "sab ----> e\n",
      "abe ----> l\n",
      "bel ----> l\n",
      "ell ----> a\n",
      "lla ----> .\n",
      "sophia\n",
      "... ----> s\n",
      "..s ----> o\n",
      ".so ----> p\n",
      "sop ----> h\n",
      "oph ----> i\n",
      "phi ----> a\n",
      "hia ----> .\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3   #content length: how many chracters do we take to predict the next one?\n",
    "X, Y = [], []\n",
    "for w in words[:5]:\n",
    "\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(''.join(itos[i] for i in context), '---->', itos[ix])\n",
    "\n",
    "        #crop and append\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80d560d3-2c98-4046-b5c9-49132eff7501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17c8b6d4-d441-4fd5-a752-3fcdfe482df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((27,2))  #2 dimension embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5d9e835-bf56-4851-93bc-1d08d94e0129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0298, 1.0701])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a70c29e-8da1-4e26-9800-f11f4f9dfcf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0298, 1.0701])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(5), num_classes=27).float() @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "200822a2-eedd-4cce-85ec-574ed95fb3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0298,  1.0701],\n",
       "        [ 2.7273, -1.4027],\n",
       "        [ 1.0933, -0.6301],\n",
       "        [ 1.0933, -0.6301],\n",
       "        [ 1.0933, -0.6301]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[torch.tensor([5,6,7,7,7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e08a58e2-4863-453f-bfd3-20148c15da54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46265e60-1940-4d05-882c-2c5ddd20cef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[13,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91fcef02-2098-4db2-88d7-446feeded6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.7667, -0.9673])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X][13,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9aad8302-434e-4e43-8a52-6b49d85db4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.7667, -0.9673])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2beb7d88-153b-4bbe-825b-8f78be7ecc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c0de514-f247-4074-866a-3d0b7956e129",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn((6, 100))  #(no.of inputs, neurons)      #no. of i/p-> (batch)*(2d-embd)\n",
    "b1 = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52847f16-ccc0-4bc3-9fa6-b1634cf8b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#emb @ w1 + b1   # 32,3,2 @ 6,100   not possible need to concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccfcdb93-1e66-4d9b-ad80-fd1c2791e554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb[:, 0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c8b1e81-8c6d-49af-85fd-18b74034bd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]], 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3327133c-02ce-4c38-a434-54948f18bb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(torch.unbind(emb, 1),1 ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "598d0e12-2bb9-4857-958b-c3f610523d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(18)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e63939db-4f8e-4611-bc33-8371b4072505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb75cdbc-2803-40e6-9248-67e186cc789e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12, 13, 14, 15, 16, 17]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(2,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "85181c85-0385-431e-8097-cbf1e95e65c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3],\n",
       "         [ 4,  5]],\n",
       "\n",
       "        [[ 6,  7],\n",
       "         [ 8,  9],\n",
       "         [10, 11]],\n",
       "\n",
       "        [[12, 13],\n",
       "         [14, 15],\n",
       "         [16, 17]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(3,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5072c3dc-7463-4cce-b25e-28e482d1a0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12106/214256462.py:1: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  a.storage()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 17\n",
       "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 18]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1fbb0240-cc0b-4351-b6d6-a87bf8e72609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(32,6).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "593e6b76-7d50-4fea-9c7a-bafdd04d2bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(32,6) == torch.cat(torch.unbind(emb, 1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8146d3e-556a-4515-b8a4-f9f7cf695249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0156,  0.9029,  1.3852,  ...,  0.1527,  1.2015,  1.3162],\n",
       "        [ 2.4521,  0.1809,  4.4049,  ..., -1.8752,  1.1763, -2.2466],\n",
       "        [ 0.7197,  6.0725,  2.1046,  ...,  0.6129,  2.5786, -1.0459],\n",
       "        ...,\n",
       "        [ 4.7558, -4.4562,  0.5370,  ..., -3.4186, -0.9359,  1.9618],\n",
       "        [ 3.7840,  2.2373,  3.0705,  ..., -4.9853,  1.8427, -2.6250],\n",
       "        [-2.0735,  4.3307,  0.5233,  ...,  5.3070,  2.2392,  3.9314]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(32,6) @ W1 + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "40b254dc-79d5-45a6-87e1-003a95680e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0156,  0.9029,  1.3852,  ...,  0.1527,  1.2015,  1.3162],\n",
       "        [ 2.4521,  0.1809,  4.4049,  ..., -1.8752,  1.1763, -2.2466],\n",
       "        [ 0.7197,  6.0725,  2.1046,  ...,  0.6129,  2.5786, -1.0459],\n",
       "        ...,\n",
       "        [ 4.7558, -4.4562,  0.5370,  ..., -3.4186, -0.9359,  1.9618],\n",
       "        [ 3.7840,  2.2373,  3.0705,  ..., -4.9853,  1.8427, -2.6250],\n",
       "        [-2.0735,  4.3307,  0.5233,  ...,  5.3070,  2.2392,  3.9314]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(emb.shape[0], 2*block_size) @ W1 + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9d555fa9-83e0-4218-ae57-3e380bd85d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0156,  0.9029,  1.3852,  ...,  0.1527,  1.2015,  1.3162],\n",
       "        [ 2.4521,  0.1809,  4.4049,  ..., -1.8752,  1.1763, -2.2466],\n",
       "        [ 0.7197,  6.0725,  2.1046,  ...,  0.6129,  2.5786, -1.0459],\n",
       "        ...,\n",
       "        [ 4.7558, -4.4562,  0.5370,  ..., -3.4186, -0.9359,  1.9618],\n",
       "        [ 3.7840,  2.2373,  3.0705,  ..., -4.9853,  1.8427, -2.6250],\n",
       "        [-2.0735,  4.3307,  0.5233,  ...,  5.3070,  2.2392,  3.9314]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(emb.shape[0], 6) @ W1 + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dbd984f6-0b9e-47ef-8ef6-9c774238f891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7681,  0.7177,  0.8821,  ...,  0.1515,  0.8341,  0.8658],\n",
       "        [ 0.9853,  0.1789,  0.9997,  ..., -0.9541,  0.8263, -0.9779],\n",
       "        [ 0.6167,  1.0000,  0.9707,  ...,  0.5462,  0.9886, -0.7802],\n",
       "        ...,\n",
       "        [ 0.9999, -0.9997,  0.4907,  ..., -0.9979, -0.7333,  0.9612],\n",
       "        [ 0.9990,  0.9775,  0.9957,  ..., -0.9999,  0.9511, -0.9896],\n",
       "        [-0.9689,  0.9997,  0.4802,  ...,  1.0000,  0.9776,  0.9992]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4c81f265-e583-400b-ac30-bc230e2d5837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "97266a33-9330-473e-a0bd-7c31ce68cb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(emb.view(-1,6) @ W1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e177bfd7-7bef-41a8-a450-9a7c0c939a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a97ad14a-7480-4398-b851-2fa431621f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# broadcasting\n",
    "# 32, 100\n",
    "#  1 , 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3b8dd807-1c90-437d-b313-5106a14b514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "078e4224-2eb0-4822-87ef-c0a3153c2fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "680ce1c2-a6f1-4e2a-bccb-f33bb3da08a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fa00c10c-3f02-4f4b-824c-b3ac30d0ea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eda0b504-80d0-43f1-9552-d3048fa04988",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = counts / counts.sum(1, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4492e94b-97b9-4034-8734-f46f84a7e0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9df01c34-1c63-4a30-841b-532f59e36d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a952f045-899f-4247-8202-e0b1a4fd205e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.3580)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -prob[torch.arange(32), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ef07190a-a23d-49a8-bb7c-44bb49dcd64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0d681597-0634-41dd-ad84-9bc2ff59ebd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a9177d48-96c5-4fad-8be6-e6d606d0f351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.3580)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(logits, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a223cae-1196-4641-b067-818999a9072d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
